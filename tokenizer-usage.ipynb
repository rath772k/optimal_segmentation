{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import GPT2Tokenizer, OptimalGPT2Tokenizer, OptimalTiktokenTokenizer\n",
    "import tiktoken\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyTiktokenTokenizer:\n",
    "    def __init__(self, model_name):\n",
    "        self.encoder = tiktoken.encoding_for_model(model_name)\n",
    "    \n",
    "    def bpe(self, word):\n",
    "        return \" \".join(self.encoder.decode([token]) for token in self.encoder.encode(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'OptimalGPT2Tokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of Vocab Initialized is 50257\n",
      "Len of Vocab Initialized is 100256\n"
     ]
    }
   ],
   "source": [
    "tokenizers = {\n",
    "    \"gpt2_greedy\": GPT2Tokenizer.from_pretrained(\"gpt2\"),\n",
    "    \"gpt2_optimal\": OptimalGPT2Tokenizer.from_pretrained(\"gpt2\"),\n",
    "    \"gpt4_greedy\": GreedyTiktokenTokenizer(\"gpt-4\"),\n",
    "    \"gpt4_optimal\": OptimalTiktokenTokenizer(\"gpt-4\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"policymaker\"]\n",
    "results = []\n",
    "for sample in samples:\n",
    "    results.append(\n",
    "        {\n",
    "            name: tokenizer.bpe(sample)\n",
    "            for name, tokenizer in tokenizers.items()\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt2_greedy</th>\n",
       "      <th>gpt2_optimal</th>\n",
       "      <th>gpt4_greedy</th>\n",
       "      <th>gpt4_optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p olic ym aker</td>\n",
       "      <td>policy maker</td>\n",
       "      <td>p olic ym aker</td>\n",
       "      <td>policy maker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gpt2_greedy  gpt2_optimal     gpt4_greedy  gpt4_optimal\n",
       "0  p olic ym aker  policy maker  p olic ym aker  policy maker"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
