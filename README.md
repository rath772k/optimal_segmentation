Code for the paper[ When Every Token Counts: Optimal Segmentation for Low-Resource Language Models](https://arxiv.org/pdf/2412.06926)

The provided tokenizer is compatible with huggingface tokenizer and thus can be used with any model and tokenizer available in huggingface.
